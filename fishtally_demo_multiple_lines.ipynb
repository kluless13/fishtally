{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwn4rkVqWKLQs/7g/vxwfY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kluless13/paper2/blob/main/fishtally_demo_multiple_lines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Dependencies"
      ],
      "metadata": {
        "id": "pacXxDYv_f6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7MkAn-b_lgu",
        "outputId": "76050912-52a0-40b5-d6d1-3ce514898adf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Dec 15 04:21:19 2023       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)\n",
        "\n",
        "!pip -q install ultralytics==8.0.20\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import display, Image\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyuQ3sWwBVV8",
        "outputId": "ab91280a-8560-401e-84b0-81b02d4311d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.20 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/166.8 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the YOLOv8 model\n",
        "model = YOLO('/content/multiclass-wts.pt')"
      ],
      "metadata": {
        "id": "0W9admJwv9zn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASS_NAMES_DICT = model.model.names\n",
        "print(CLASS_NAMES_DICT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkDRDTKjwAcW",
        "outputId": "e061e1e8-ac93-49c1-f2a6-f777784a160a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'Blue-Tang', 1: 'Orange-Clown', 2: 'Three-Striped-Damselfish', 3: 'Yellow-Tang'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FishTally - 2 lines"
      ],
      "metadata": {
        "id": "burjbAj1CNVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from collections import defaultdict\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('/content/multiclass-wts.pt')\n",
        "\n",
        "# Set up video capture\n",
        "cap = cv2.VideoCapture(\"/content/Yellow Tang.mp4\")\n",
        "\n",
        "# Define first line coordinates\n",
        "START = sv.Point()\n",
        "END = sv.Point()\n",
        "\n",
        "# Define second line coordinates\n",
        "START2 = sv.Point()\n",
        "END2 = sv.Point()\n",
        "\n",
        "# Store the track history\n",
        "track_history = defaultdict(lambda: [])\n",
        "\n",
        "# Create a dictionary to keep track of objects that have crossed the line\n",
        "crossed_objects = {}\n",
        "\n",
        "# Dictionary for second line\n",
        "crossed_objects2 = {}\n",
        "\n",
        "# Open a video sink for the output video\n",
        "video_info = sv.VideoInfo.from_video_path(\"\")\n",
        "with sv.VideoSink(\"fishtally_multi_line_1.mp4\", video_info) as sink:\n",
        "\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "\n",
        "        if success:\n",
        "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "            results = model.track(frame, classes=[3], persist=True, save=True, tracker=\"bytetrack.yaml\")\n",
        "\n",
        "            # Get the boxes and track IDs\n",
        "            boxes = results[0].boxes.xywh.cpu()\n",
        "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "            # Visualize the results on the frame\n",
        "            annotated_frame = results[0].plot()\n",
        "            detections = sv.Detections.from_yolov8(results[0])\n",
        "\n",
        "            # Plot the tracks and count objects crossing the line\n",
        "            for box, track_id in zip(boxes, track_ids):\n",
        "                x, y, w, h = box\n",
        "                track = track_history[track_id]\n",
        "                track.append((float(x), float(y)))  # x, y center point\n",
        "                if len(track) > 30:  # retain 30 tracks for 30 frames\n",
        "                    track.pop(0)\n",
        "\n",
        "                # Check if the object crosses the line\n",
        "                if START.x < x < END.x and abs(y - START.y) < 5:  # Assuming objects cross horizontally\n",
        "                    if track_id not in crossed_objects:\n",
        "                        crossed_objects[track_id] = True\n",
        "                # Check if objects have crossed line 2\n",
        "                if START2.x < x < END2.x and min(START2.y, END2.y) < y < max(START2.y, END2.y):  # Assuming objects cross horizontally\n",
        "                    if track_id not in crossed_objects2:\n",
        "                        crossed_objects2[track_id] = True\n",
        "\n",
        "                    # Annotate the object as it crosses the line\n",
        "                    cv2.rectangle(annotated_frame, (int(x - w / 2), int(y - h / 2)), (int(x + w / 2), int(y + h / 2)), (0, 255, 0), 2)\n",
        "\n",
        "            # Draw the lines on the frame\n",
        "            cv2.line(annotated_frame, (START.x, START.y), (END.x, END.y), (0, 255, 0), 2)\n",
        "            cv2.line(annotated_frame, (START2.x, START2.y), (END2.x, END2.y), (0, 255, 0), 2)\n",
        "\n",
        "            # Write the count of objects on each frame\n",
        "            count_text = f\"Objects crossed: {len(crossed_objects)}\"\n",
        "            count_text2 = f\"Objects crossed: {len(crossed_objects2)}\"\n",
        "            cv2.putText(annotated_frame, count_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            cv2.putText(annotated_frame, count_text2, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            # Write the frame with annotations to the output video\n",
        "            sink.write_frame(annotated_frame)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# Release the video capture\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "SKLXNk7MCE6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FishTally - multiple lines"
      ],
      "metadata": {
        "id": "xIMZk4-kJYEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from collections import defaultdict\n",
        "import supervision as sv\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('')\n",
        "\n",
        "# Set up video capture\n",
        "cap = cv2.VideoCapture(\"\")\n",
        "\n",
        "START = sv.Point()\n",
        "END = sv.Point()\n",
        "START2 = sv.Point()\n",
        "END2 = sv.Point()\n",
        "START3 = sv.Point()\n",
        "END3 = sv.Point()\n",
        "\n",
        "# Store the track history\n",
        "track_history = defaultdict(lambda: [])\n",
        "\n",
        "crossed_objects = {}\n",
        "crossed_objects2 = {}\n",
        "crossed_objects3 = {}\n",
        "\n",
        "# Open a video sink for the output video\n",
        "video_info = sv.VideoInfo.from_video_path(\"\")\n",
        "with sv.VideoSink(\"fishtally_multi_line_2.mp4\", video_info) as sink:\n",
        "\n",
        "    while cap.isOpened():\n",
        "        success, frame = cap.read()\n",
        "\n",
        "        if success:\n",
        "            # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "            results = model.track(frame, classes=[], persist=True, save=True, tracker=\"bytetrack.yaml\")\n",
        "\n",
        "            # Get the boxes and track IDs\n",
        "            boxes = results[0].boxes.xywh.cpu()\n",
        "            track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "            # Visualize the results on the frame\n",
        "            annotated_frame = results[0].plot()\n",
        "            detections = sv.Detections.from_yolov8(results[0])\n",
        "\n",
        "            # Plot the tracks and count objects crossing the line\n",
        "            for box, track_id in zip(boxes, track_ids):\n",
        "                x, y, w, h = box\n",
        "                track = track_history[track_id]\n",
        "                track.append((float(x), float(y)))  # x, y center point\n",
        "                if len(track) > 30:  # retain 30 tracks for 30 frames\n",
        "                    track.pop(0)\n",
        "\n",
        "                if START.x < x < END.x and abs(y - START.y) < 5:\n",
        "                    if track_id not in crossed_objects:\n",
        "                        crossed_objects[track_id] = True\n",
        "\n",
        "                if START2.x < x < END2.x and min(START2.y, END2.y) < y < max(START2.y, END2.y):\n",
        "                    if track_id not in crossed_objects2:\n",
        "                        crossed_objects2[track_id] = True\n",
        "\n",
        "                if START3.x < x < END3.x and min(START3.y, END3.y) < y < max(START3.y, END3.y):\n",
        "                    if track_id not in crossed_objects3:\n",
        "                        crossed_objects3[track_id] = True\n",
        "\n",
        "                    # Annotate the object as it crosses the line\n",
        "                    cv2.rectangle(annotated_frame, (int(x - w / 2), int(y - h / 2)), (int(x + w / 2), int(y + h / 2)), (0, 255, 0), 2)\n",
        "\n",
        "            cv2.line(annotated_frame, (START.x, START.y), (END.x, END.y), (0, 255, 0), 2)\n",
        "            cv2.line(annotated_frame, (START2.x, START2.y), (END2.x, END2.y), (0, 255, 0), 2)\n",
        "            cv2.line(annotated_frame, (START3.x, START3.y), (END3.x, END3.y), (0, 255, 0), 2)\n",
        "\n",
        "            # Write the count of objects on each frame\n",
        "            count_text = f\"Objects crossed: {len(crossed_objects)}\"\n",
        "            count_text2 = f\"Objects crossed: {len(crossed_objects2)}\"\n",
        "            cv2.putText(annotated_frame, count_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "            cv2.putText(annotated_frame, count_text2, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            # Write the frame with annotations to the output video\n",
        "            sink.write_frame(annotated_frame)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# Release the video capture\n",
        "cap.release()"
      ],
      "metadata": {
        "id": "WSg4IqH9JEny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}